# 무엇이 게 인가?
![image](https://user-images.githubusercontent.com/69780812/139018320-b9e2ad56-b3fe-46bd-8b7c-5995e4339b75.png)

- 우리는 단번에 게 라는 것을 알아 차릴 수 있다.

![image](https://user-images.githubusercontent.com/69780812/139018387-80534886-9c9c-4081-9513-740d67fe3f65.png)

- 역시 게 라는 사실을 알아 차릴 수 있다.
- 모양과 색깔이 달라도 알아 차린다.. 신기하다..

![image](https://user-images.githubusercontent.com/69780812/139018503-2364de0b-539d-4df9-a2d6-d74ef9f1db44.png)

- 진흙과 비슷한 컬러를 하고있더라도, 이 전에 봤던 게와 너무나 다른 모양임에도 게 라는 사실을 안다.
- 아주 간략이 특징만 뽑아낸 그림에서도 게 라는 사실을 안다.

![image](https://user-images.githubusercontent.com/69780812/139018602-95cddb79-20d0-48c8-9715-61b2068f464f.png)

- 과연 이것은 게 일까? 게라고하는 사람도 있을 것 같다.
- 거미를 전혀 모르거나 본사람이 없다면 적어도 게라고하는 사람은 완전 소수일 거다.

- 학습은 단순 암기(memorization)이 아니고, 학습의 과정을 통해 자신도 모르는 사이 일반화(generalization)과정을 거치게 되며 이를 통해 새로운 무엇을 접하더라도 예측(Prediction)할 수 있는 능력을 갖게하는 것을 말한다.

![image](https://user-images.githubusercontent.com/69780812/139018851-66b9a7ec-f70e-4f73-88e6-bca038d33982.png)

- 이것은 코코넛 크랩이다.
- 거미같이 생겼지만 집게를 갖고있으며 코코넛 열매를 좋아하는 게이다.
- 몰랐는가 ? 재학습하면된다.
- 학습을 통해 오류가 발생하더라도 우리는 재교육을 통해 오류를 보정한다.
  - 꾸중, 망신 당하기 등의 학습 방법도 있고, 코코넛 크랩을 잡기위해 고생하는 과정 등을 보며 학습하는 방법도 있다.
  - 시청각 자료를 학습의 보조 수단으로 사용하여 학습 효과를 높일 수도 있다.
  - 이처럼 학습 방법은 학습 속도와 질을 결정하게 된다.

- 종합하면 학습이라는 것은 학습에 사용한 데이터로부터 뭔가 중요한 특징을 끄집어내고, 그 특징으로부터 일반화를 거쳐 예측할 수 있는 능력을 세우는 것을 말한다.
- 데이터 수가 적으면 학습하더라도 오류가 발생할 수 있으며 오류가 발생하면 재학습을 통해 학습의 질을 높일 수 있다.
  - 물론 처음부터 데이터 수가 많으면 학습의 질은 개선될 것이다.
- 단순히 비슷한 모양의 게 사진만 많이 보면 코코넛 크랩처럼 희귀한 형태에 대해 알기 어렵다. 학습에 사용하는 데이터의 '양'만 중요한 것이 아니라 '질'도 매우 중요하다는 것을 알 수 있다.

# 인간의 두뇌
- 사람의 학습은 두뇌를 통해 이루어진다.

![image](https://user-images.githubusercontent.com/69780812/139019660-b9829637-7580-4c7a-b22b-26e676a092b1.png)

- 이성이나 추론 : 전두엽
- 시각 : 후두엽
- 청각 이나 기억 : 측두엽
- 사람의 두뇌에는 약 1000억개 되는 뇌세포가 있는데 뇌세포는 서로 복잡하게 연결되어 있으며 뇌세포 1개당 1000개 정도의 시냅스가 만들어진다고한다.
  - 그 연결 관계의 복잡도는 예측할 수 없다..

![image](https://user-images.githubusercontent.com/69780812/139019849-8e27888a-4913-4d86-8f07-5c43dcbce86e.png)

- Soma(세포체) : 세포로 들어온 신호의 수준을 판단하여 일정 수준 이하 신호는 무시, 일정 수준 넘으면 신호에 응답하여 다음 세포로 신호를 전송
  - 세포체는 Activation Function 기능을 담당한다.
- Dendrite(수상돌기) : 세포로 전달되는 신호를 받아들이는 부분
- Axon(축삭돌기) : 세포에서 다른 세포로 신호를 전달하는 부분
- Synapse(시냅스) : 수상돌기와 축삭돌기 사이에 있는 부분, 신호 전달의 세기(Weight)를 담당한다.
  - 학습에 있어 매우 중요한 역할
  - 어떤 세포의 축삭돌기로 부터 전달된 신호를 다음 세포로 보낼 때 가중치를 결정하며 0과 1사이의 범위의 숫자를 곱해주는 것으로 이해하면 된다.
  - 0 : 모든 신호 무시
  - 1 쪽으로 갈수록 신호의 손실 없이 그대로 전달
  - 학습하게 되면 이 시냅스의 세기가 바뀌게 된다.
  - 각 세포로 연결되는 수 많은 시냅스의 세기(weight)가 학습의도에 따라 변하게 되는 것이다.

# Hebbian Rule
- 1949s, Donald Hebb
  - 학습이란 시냅스 연결의 세기를 결정하는 것으로 정의
- 2개의 연결된 세포가 동시에 활성화 되는 경우 시냅스의 세기를 올리는 것이라고 했다.
  - Hebbian Rule
- 세포 수준에서의 학습이 어떤 의미를 갖는지 확인할 수 있기에 비슷한 개념으로 머신 러닝을 시도하게된다.
  - 시냅스(Weight), 세포체(Activation Function)의 개념을 갖는 인공 뉴런을 만들면 학습이 가능해진다.

# 인공 신경망의 기본 셀
![image](https://user-images.githubusercontent.com/69780812/139020642-9c0495c2-b6d7-4ef8-841d-a929ef63def2.png)

![image](https://user-images.githubusercontent.com/69780812/139020675-c5ef673a-191d-4339-b8b9-6fa158c47009.png)

- 인공 신경망의 전체 구성이다.
- 일정 값에 따라 0 or -1을 출력하므로 단수하지만 학습의 기본이 되는 세포의 모든 요소를 갖추고 있어 머신 러닝의 길이 열리게된다.
- 위 기본 구조는 1957, Rosenbalt에 의해 처음 고안되었으며 **Perceptron**이라는 일므으로 불린다.
  - 신경망의 시초다.
  - XOR 문제를 풀 수 없다는 사실을 발견하게 실망하게 된다.
  - 요즘 사용되는 인공 뉴런의 구조는 처음 발표된 퍼셉트론과는 좀 달라졌지만 현재도 계속 사용되는 용어다.

## XOR Problem
![image](https://user-images.githubusercontent.com/69780812/139020985-f28236a5-8326-40ec-9cdd-a7f200d52dd2.png)

- Perceptron의 기본 수식을 보면 Linear 성질을 갖고있으며 공간 관점에서 보면 **선형적으로 구별이 가능한 성질**을 갖게된다.
  - 선형적으로 구별이 가능한 성질 : linearly separable
  - 분류에서는 매우 유용한 성질이다.
  - 하지만, 위 성질은 XOR 문제와 같은 기본 문제도 풀수 없다는 것이 밝혀지게 된다.
  - Multi layer 로 해결하게 된다.
- 위 그림을 봤을 때, AND, OR, NOT 등을 구현하는 것은 전혀 문제가 없다. 하지만 XOR을 구현할 방법이 없다.
  - 결과적으로 선형적 특성만으로는 한계가 있으므로 비선형적인 무언가가 필요하다.

![image](https://user-images.githubusercontent.com/69780812/139021426-f6cd6582-2f25-45cc-946c-ff3cada4bb7c.png)

- Perceptron의 활성화 함수는 Sign or Step Function이다.
  - 비선형 조건을 표현할 길이 없다.
- 결과적으로 대부분의 신경망은 Sigmoid 함수나 Hyperbolic tangent와 같은 비선형 활성함수를 사용하게된다.
  - Sigmoid를 사용하면서 많은 것들을 쉽게 표현할 수 있게 되지만, 망이 깊어지면서 DNN의 학습 어려움으로 ReLU(2011)를 주로 사용한다.

# 머신러닝이 필요한 분야
- 명쾌하기 정의하기 어려운 경우 - 얼굴 인식
- 많은 양의 데이터 속 내재되어 있는 정보를 해석해야 하는 경우 - 빅데이터 분석
- 특정 분야에 대한 지식이 너무 방대하여 일일이 코딩하기 어려운 경우 - 의료진단
- 환경이 시간에 따라 변하는 경우

# 머신러닝 가능하게된 이유
- 대용량 저장 장치의 가격 하락
- 학습에 이용할 수 있는 데이터의 증가
- 강력한 GPU로 무장한 컴퓨터의 성능 증가
- GPU 효과적으로 사용할 수 있는 라이브러리 개발 및 공급
- 훌륭한 머신러닝 알고리즘들

# 머신러닝 & 일반적 프로그래밍 차이
![image](https://user-images.githubusercontent.com/69780812/139022427-41ee0a3f-20da-4ba4-a636-294ade76a5a8.png)

- 일반적 프로그래밍 : 프로그램을 짜고 데이터를 넣어주면 기대했던 출력이 나오는 방식
- 머신러닝 : 데이터를 입력하고 그 데이터가 입력 되면 나오는 출력을 넣어주면 학습을 통해 프로그램을 만들어낸다.

# 머신러닝 Framework
- 머신 러닝이란 학습 집합을 이용해서 예측 함수 F를 만들어 내는 과정이라 생각할 수 있다.
  - y = f(x)
  - x : 입력
  - y : 출력
  - f : 학습을 통해 만들어진 프로그램

## Training
![image](https://user-images.githubusercontent.com/69780812/139022696-1d82c228-23fb-40b3-8df4-1fa08ce87b22.png)

- 학습 데이터를 이용해 예측 함수를 구하는 과정
- 학습을 위해 label이 붙은 영상 데이터 인가
- 기대했던 label이 나오도록 학습을 진행
- 영상을 분류할 수 있는 **학습된 모델(예측함수 F)**가 얻어진다.

# Testing
![image](https://user-images.githubusercontent.com/69780812/139022909-05da2c73-97c9-49c3-9bfd-72a24249ad0b.png)

- 학습이 잘 되었다면 "사과"를 출력한다.
- 만약 검사에서 잘못된 결과가 나오면 다시 학습을 시키면 된다.
- 학습과 검사로 간단하게 나누는 대신 Validation 과정을 넣기도 한다.
  - 학습과 다른 데이터를 이용해 학습이 제대로 되었는지를 확인하는 것을 말한다.
  - 너무 주어진 학습 데이터에 특화되면 학습 데이터에 조금만 벗어나도 결과가 나쁘게 나올 수 있다 : **Overfitting**
---
- 결국 학습이란 주어진 학습 데이터를 통해 사용하지 않은 새로운 데이터를 얼마나 잘 판단할 수 있는지 일반화(Generalization)의 과정이라고 볼 수 있다.
- 머신 러닝이란
  - 특정 개념(Concept)을 갖고 있는 label이 붙어 있는 학습 데이터를 준비해야한다.
  - 이 데이터들은 특징을을 이용해 설명이나 묘사할 수 있다.
  - 머신 러닝 알고리즘은 학습 데이터가 갖고있는 특징들을 이용해 예측함수(학습 모델)을 만들어 낸다.
  - 학습 모델은 아직 label이 없는 새로운 데이터에 대해 학습된 모델을 이용해 예측/판단을 한다.

# 머신 러닝의 학습 알고리즘
![image](https://user-images.githubusercontent.com/69780812/139024029-fbd7ffdf-bb01-4a5c-8027-9155418c5bcf.png)

- 일반적인 분류 방법은 크게 3가지로 분류 가능하다.
  - 지도 학습 (Supervised Learning)
  - 자율 학습 (Unsupervised Learning)
  - 강화 학습 (Reinforcement Learning)

## 지도 학습
- 주어진 입력에 대해 어떤 결과가 나올지 알고 있는 학습데이터를 이용해 데이터를 해석할 수 있는 모델을 만들고 그것을 바탕으로 새로운 데이터를 추정하는 방법이다.
  - 수치해석 방법으로 조금씩 최적값을 찾아가는 과정을 반복적으로 수행
  - 학습데이터를 인가하고 기대값이 나올 수 있게 변수를 조금씩 수정해 가는 방식으로 학습을 진행

## 비지도 학습
- 학습 데이터에 대한 기대값이 붙어 있지 않다.
- 학습 알고리즘을 통해 학습 데이터 속 어떤 패턴이나 숨어있는 중요한 핵심 컨셉을 찾아 학습하는 것이다.
  - 각 과일들이 색깔, 모양, 크기, 향기 등으로 분류될 수 있는 것처럼 특징으로 분류하는 방식
- 특정 가이드가 없어 어렵고, 연구가 더 필요하다.

## 강화학습
- 훈련을 잘따르면 Reward, 그렇지 못하면 Punishment를 줘서 훈련의 감독관이 원하는 방향으로 학습하게 된다.
  - 경우의 수가 너무 많아 옳고 그른 것들에 대해 사전에 명확하게 기술하기 어려운 경우에 적합한 학습 방법이다.
  - 자율주행, 전략 시뮬레이션 등 상황에 따라 다양한 대응할 수 있는 응용에 적합한 방법이다.
  